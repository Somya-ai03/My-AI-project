{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d775d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1 system prompt: You're a test engineer, ...\n",
    "# step2: instantiate openAI\n",
    "# Step3: add dq.md as a knowledge to chatgpt\n",
    "# Step4: User prompt- run the data profiler and generate the report as sample data for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI    # ensure you have the correct OpenAI client installed\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONFIG ----------\n",
    "DQ_PATH = \"/Users/somyak/projects/llm_engineering/keyrus_agentic_testing_framework/data_profiler_tool/dq.md\"               # path to your dq.md file you created\n",
    "DATA_PATH = \"/Users/somyak/projects/llm_engineering/keyrus_agentic_testing_framework/dummy_data_profiler_1000000_rows.csv\"     # path to your dummy master data (update if different)\n",
    "OUTPUT_PATH = \"/Users/somyak/projects/llm_engineering/keyrus_agentic_testing_framework/data_profiler_tool\"\n",
    "MODEL = \"gpt-4.1-nano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------Load environment variables in a file called .env--------------------------\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai = OpenAI()\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e6807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- helper: system prompt ----------\n",
    "SYSTEM_PROMPT = \"\"\"You are an AI Data Test Engineer designed to automate the end-to-end data profiling workflow for the PADS project.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Load and use all Data Quality Rules contained in the knowledge file 'dq.md' that I uploaded.\n",
    "2. Understand the workflow:\n",
    "   - Input: raw master dataset (UAT extract).\n",
    "   - After import to SQL, three columns are added: RecordId, CreationDate, {TLA}_Filter.\n",
    "   - Profiling is applied on the enriched master table.\n",
    "3. Apply every DQ rule from dq.md (null checks, duplicates, datatypes, allowed values, cross-column rules, range/quartiles/outliers).\n",
    "4. Run variance profiling according to dq.md (ALL, RANGE, TOPVALUE, DISTINCT, POSITIVENEGATIVE when applicable).\n",
    "5. Compute ValueCount, ValueDistribution (pct), VarianceHitCount, VarianceHitRank, VarianceHitDenseRank, Quartile, SumValueDistribution, and select representative RecordId(s) for testing.\n",
    "6. Output: (a) a brief profiling summary, and (b) the final sample dataset (rows) — exported as CSV rows where each row is a record from the original master data.\n",
    "7. NEVER invent new rules — always use dq.md as the source of truth.\n",
    "\n",
    "Important:\n",
    "- For the large dataset, you can read the top N rows locally for context, but you must base decisions on the full dataset.\n",
    "- Provide the final sample data as CSV text (so it can be parsed and saved).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- helper: user prompt (concise) ----------\n",
    "USER_PROMPT = f\"\"\"\n",
    "I have uploaded a DQ rules file at this local path (on the same host): {DQ_PATH}\n",
    "I have a master dataset at: {DATA_PATH}\n",
    "\n",
    "Please:\n",
    " 1) Load the DQ rules from the file at the local path above.\n",
    " 2) Apply those rules to the dataset at the local path above.\n",
    " 3) Add RecordId, CreationDate, POLICY_Filter if missing (RecordId sequential).\n",
    " 4) Compute profiling metrics and pick ~30-50 representative sample rows.\n",
    " 5) Output: (A) a short profiling summary, and (B) the final sample CSV between\n",
    "    markers: ===SAMPLE_CSV=== (start) and ===END_SAMPLE_CSV=== (end).\n",
    "Return only the summary followed by the CSV block. The platform will transform the local path to a URL and make that file available to you; use that file as the single source of truth for DQ rules.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sending request to agent... (may take some seconds)\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": USER_PROMPT}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    files=[\n",
    "        {\"file_url\": DQ_PATH},\n",
    "        {\"file_url\": DATA_PATH}\n",
    "    ]\n",
    ")\n",
    "\n",
    "assistant_text = response.choices[0].message[\"content\"]\n",
    "print(assistant_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b09805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "MODEL = \"gpt-4.1-nano\"\n",
    "\n",
    "DQ_PATH = \"/Users/somyak/projects/llm_engineering/keyrus_agentic_testing_framework/data_profiler_tool/dq.md\"\n",
    "DATA_PATH = \"/Users/somyak/projects/llm_engineering/keyrus_agentic_testing_framework/dummy_data_profiler_1000000_rows.csv\"\n",
    "OUTPUT_CSV = \"/Users/somyak/projects/llm_engineering/keyrus_agentic_testing_framework/data_profiler_tool/profiler_sample_output_from_agent.csv\"\n",
    "\n",
    "SYSTEM_PROMPT = \"You are an AI Data Test Engineer. Use ONLY the DQ rules file provided in the FILE_URLS block. Do not invent rules.\"\n",
    "USER_INTENT = (\n",
    "    \"Please load the files listed in the FILE_URLS block (they are local paths on the host), \"\n",
    "    \"apply the dq.md rules to the master CSV, and return a final sample CSV between markers.\"\n",
    ")\n",
    "\n",
    "# Structured file-list message - platform will detect these local paths and host them for the agent/tool.\n",
    "file_list_message = (\n",
    "    \"FILE_URLS:\\n\"\n",
    "    f\"- {DQ_PATH}\\n\"\n",
    "    f\"- {DATA_PATH}\\n\\n\"\n",
    "    \"The platform will transform these local paths into hosted URLs the agent can access. \"\n",
    "    \"Now: perform the profiling as specified below.\"\n",
    ")\n",
    "\n",
    "USER_PROMPT = (\n",
    "    file_list_message + \"\\n\\n\"\n",
    "    + \"TASK:\\n\"\n",
    "    \"1) Load the DQ rules from the dq.md file path above.\\n\"\n",
    "    \"2) Load the master dataset from the CSV path above.\\n\"\n",
    "    \"3) If missing, add RecordId (sequential), CreationDate (today), and POLICY_Filter='ALL'.\\n\"\n",
    "    \"4) Apply every DQ rule from dq.md, compute profiling metrics, variance groups, quartiles, etc.\\n\"\n",
    "    \"5) Select ~30-50 representative records covering top/mid/low frequency buckets and Premium ranges.\\n\"\n",
    "    \"6) Output:\\n\"\n",
    "    \"   - A short profiling summary, then\\n\"\n",
    "    \"   - The final sample CSV **only** between these markers:\\n\"\n",
    "    \"     ===SAMPLE_CSV===\\n\"\n",
    "    \"     <csv header + rows>\\n\"\n",
    "    \"     ===END_SAMPLE_CSV===\\n\"\n",
    "    \"Return nothing after the end marker.\"\n",
    ")\n",
    "\n",
    "def call_agent_with_retries(max_attempts=5, pause_seconds=8):\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        print(f\"[attempt {attempt}] sending request to agent...\")\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": USER_PROMPT}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=8000\n",
    "        )\n",
    "\n",
    "        # extract assistant content robustly\n",
    "        try:\n",
    "            assistant_text = resp.choices[0].message[\"content\"]\n",
    "        except Exception:\n",
    "            assistant_text = str(resp)\n",
    "\n",
    "        # quick diagnostic\n",
    "        preview = assistant_text[:800].strip()\n",
    "        print(\"assistant preview:\", preview.replace(\"\\n\", \" \")[:300])\n",
    "\n",
    "        # If assistant returned only an acknowledgement (\"I will do X\"), retry after pause\n",
    "        ack_keywords = [\n",
    "            \"i will now proceed\",\n",
    "            \"please hold on\",\n",
    "            \"i will proceed\",\n",
    "            \"processing these steps\",\n",
    "            \"i will now process\"\n",
    "        ]\n",
    "        lower = assistant_text.lower()\n",
    "        if any(k in lower for k in ack_keywords):\n",
    "            if attempt < max_attempts:\n",
    "                print(\"Assistant acknowledged but did not return CSV. Waiting and retrying...\")\n",
    "                time.sleep(pause_seconds)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Max attempts reached. Assistant never returned CSV. Raw response:\\n\")\n",
    "                print(assistant_text[:4000])\n",
    "                return None\n",
    "\n",
    "        # Try to extract CSV between markers\n",
    "        start = \"===SAMPLE_CSV===\"\n",
    "        end = \"===END_SAMPLE_CSV===\"\n",
    "        if start in assistant_text and end in assistant_text:\n",
    "            csv_block = assistant_text.split(start, 1)[1].split(end, 1)[0].strip()\n",
    "            if \",\" in csv_block and \"\\n\" in csv_block:\n",
    "                print(\"CSV found. Saving to:\", OUTPUT_CSV)\n",
    "                with open(OUTPUT_CSV, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(csv_block)\n",
    "                return OUTPUT_CSV\n",
    "            else:\n",
    "                print(\"Found markers but content does not look like CSV. Dumping snippet:\")\n",
    "                print(csv_block[:1000])\n",
    "                return None\n",
    "        else:\n",
    "            # No markers and no obvious ACK => print a bit and retry once\n",
    "            if attempt < max_attempts:\n",
    "                print(\"No CSV markers found. Retrying after short pause...\")\n",
    "                time.sleep(pause_seconds)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"No CSV markers after retries. Final assistant output (truncated):\\n\")\n",
    "                print(assistant_text[:4000])\n",
    "                return None\n",
    "\n",
    "# Run\n",
    "result_path = call_agent_with_retries(max_attempts=6, pause_seconds=10)\n",
    "if result_path:\n",
    "    print(\"Agent-produced CSV available at:\", result_path)\n",
    "else:\n",
    "    print(\"Agent did not return CSV. See logs above for assistant output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05743c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
